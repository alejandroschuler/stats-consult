<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.55">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>dialogue</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="dialogue_files/libs/clipboard/clipboard.min.js"></script>
<script src="dialogue_files/libs/quarto-html/quarto.js"></script>
<script src="dialogue_files/libs/quarto-html/popper.min.js"></script>
<script src="dialogue_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="dialogue_files/libs/quarto-html/anchor.min.js"></script>
<link href="dialogue_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="dialogue_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="dialogue_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="dialogue_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="dialogue_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#example-consult-dialogue" id="toc-example-consult-dialogue" class="nav-link active" data-scroll-target="#example-consult-dialogue">Example Consult Dialogue</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">




<section id="example-consult-dialogue" class="level1">
<h1>Example Consult Dialogue</h1>
<p><strong>Client:</strong> I’m trying to figure out how many people I need to enroll in my study. I’m pre-registering the study, so I need to show a power calculation to demonstrate that I will have enough people to demonstrate the effect I’m looking for. I’m researching the effect of a life coaching intervention that my lab has designed. Participants are randomized to either receive our life coaching or a sham intervention, after which they are asked to write any number of life goals for themselves. We are particularly interested in the number of goals that they write that we classify as “relational,” i.e., they pertain to improving their relationships with others.</p>
<p><strong>Consultant:</strong> Ok, great, I think I can help you with that. The first thing you need to know is how you will analyze the data at the end of your study. Are you just looking to find a difference in the mean number of relational goals between the two treatment groups?</p>
<p><strong>Client:</strong> Yes, that sounds right, but I also want to control for the total number of goals that someone writes. In a pilot experiment with ~100 participants, we saw that different people write different numbers of total goals, and that if we included the number of total goals in a linear regression the effect of the treatment became more significant.</p>
<p><strong>Consultant:</strong> Hmmm, that’s a good point. But I think that adjusting for the total number of goals like that might mess up your estimate of the treatment effect. It’s possible that the intervention also encourages people to write more or fewer goals overall, so the treatment and total number of goals written would be correlated, and you wouldn’t be getting just the causal effect of the treatment on the number of relational goals. Since treatment impacts total goals, some part of the coefficient of total goals is actually attributable to the treatment, but that’s not being modeled, and you’ll miss that. Is the raw number of relational goals absolutely the quantity of interest here?</p>
<p><strong>Client:</strong> Oh, I see. Well, we’re not necessarily interested in the raw number of relational goals per se—we just want to know if people are more “relationally oriented” if given the intervention. The raw number of goals is just a proxy for that. We’ve thought about looking at the ratio of relational goals to total goals and seeing if that quantity changes with the intervention.</p>
<p><strong>Consultant:</strong> Ok, I think that’s a better outcome to use, and then you avoid having to do a mediation analysis. Let’s move forward using that outcome. So you’re interested in seeing if an individual-level proportion is different in two populations… since that’s an outcome that is fixed between zero and one, a logistic regression comes to mind. Do you know about logistic regressions?</p>
<p><strong>Client:</strong> Yes, but I thought logistic regression only worked for binary outcomes.</p>
<p><strong>Consultant:</strong> I’ve only ever seen it used in that context, but the underlying probability model should be able to handle this case. Let me show you what I mean. Logistic regression assumes that the outcomes are drawn from a binomial distribution, which models the probability of getting heads in flips of a biased coin where the probability of heads in a single flip is <span class="math inline">\(p\)</span>. Given a bunch of results of coin flips, we want to find out what <span class="math inline">\(p\)</span> is likely to be. We can assume that the probability in the two groups might be different, so <span class="math inline">\(p_T\)</span> and <span class="math inline">\(p_C\)</span> (the treatment and control probabilities) are what we’re trying to estimate. In a logistic regression, we’re generally assuming that the outcome of each participant is the result of a single flip (<span class="math inline">\(n = 1\)</span>), so you either get heads or tails for each person. In your case, however, we can see each goal that they write as a coin flip and evaluate whether or not that goal is relational as “heads”. Now we see that each participant gets a different number of opportunities to flip the coin, but the same model can just as easily account for that.</p>
<p><strong>Client:</strong> Ok, but how do I get that to work in R?</p>
<p><strong>Consultant:</strong> Good question. I’m not sure, so let’s look it up. I’ll google “logistic regression proportional outcome”… and here we go… from Stack Overflow: You can also specify the response as a proportion between 0 and 1, then specify another column as the ‘weight’ that gives the total number that the proportion is from (so a response of 0.3 and a weight of 10 is the same as 3 ‘successes’ and 7 ‘failures’).</p>
<p><strong>Client:</strong> Interesting. I think I get why we need the weights. If a person only wrote one or two goals, the fraction of those that is relational could vary a lot due to random chance, so it’s not a good estimate of the proportion. If someone wrote many goals, we can be more confident about that fraction being a decent estimate of the proportion, so we want to weight that measurement more.</p>
<p><strong>Consultant:</strong> That’s a good way of looking at it. Now let’s get back to the original question. You need to find how many people to enroll in your study so that you have enough statistical power to detect an effect of some size. In terms of the model we’ve set up, you want to test the difference between <span class="math inline">\(p_T\)</span> and <span class="math inline">\(p_C\)</span> and quantify how likely you think it is that you would see that difference in the data if in reality <span class="math inline">\(p_T = p_C\)</span>.</p>
<p><strong>Client:</strong> That’s right. But how can that help me find the number of subjects I need? By the way, if I run the analysis we’ve been talking about on my pilot data, I see that for the controls the estimate is <span class="math inline">\(p_C = 0.1\)</span> and for the treated group I get <span class="math inline">\(p_T = 0.2\)</span>, and the coefficient in the model is significant with a p-value &lt; 0.05.</p>
<p><strong>Consultant:</strong> Good. Hypothesis testing and power calculations are two sides of the same coin, so it’s important to understand what it is you are testing. Consider this picture:</p>
<p>On the x-axis are values of the coefficient of treatment in the model you run. The y-axis shows how likely certain outcomes are under certain conditions. Let’s look at the condition <span class="math inline">\(H_0: p_T = p_C\)</span>, which corresponds to <span class="math inline">\(p_T = p_C\)</span> in our story (no difference in the treatments). We call this the null hypothesis. If that’s the case, then most of the time the coefficient we get out of the model should be 0, but you can imagine that sometimes, by random chance, a larger number of people who are more relational at baseline would be assigned to one treatment, so we would get a nonzero coefficient. Since it’s less and less likely that a larger number of such people would randomly all be assigned to the same group, it’s less and less likely that the coefficient we get would be big, either positive or negative. The other condition (<span class="math inline">\(H_1: p_T - p_C = \delta\)</span>) is the alternate hypothesis that <span class="math inline">\(p_T - p_C = \delta\)</span>, which also has a distribution of results by a similar argument. The idea of hypothesis testing is that you draw a vertical line somewhere along the x-axis before you run the experiment (we call it the decision boundary), and then if the coefficient you get comes down on the left side of that boundary, you say it’s more likely that the coefficient you got came from the distribution of results under <span class="math inline">\(H_0\)</span>, so you can’t disprove that <span class="math inline">\(H_0: p_T = p_C\)</span>. If it comes down on the right side of the boundary, you say you have strong evidence that <span class="math inline">\(p_T \neq p_C\)</span> because it would be really rare to observe so large a coefficient if <span class="math inline">\(H_0\)</span> were the case.</p>
<p><strong>Client:</strong> I really like this picture. I’ve done hypothesis testing for a long time, but I’ve never understood it like this! But I still don’t see how this helps with the number of subjects I need…</p>
<p><strong>Consultant:</strong> We’re getting there! The question is: how do you decide where to put the decision boundary? Most people place it to ensure that only a small percentage (we call it the significance level <span class="math inline">\(\alpha\)</span>, which is usually 5%) of the null distribution is to the right of it—that’s represented by the solid black area.</p>
<p><strong>Client:</strong> That means that if the coefficient comes down to the right of the boundary there’s only a 5% chance that the null hypothesis is true.</p>
<p><strong>Consultant:</strong> Almost. What it means is that if the null hypothesis were true, we would only observe a coefficient this big 5% of the time we did this experiment. It’s the probability that we reject the null if the null was actually true (a false positive). What’s important to note is that there is also a striped shaded area that belongs to the distribution under <span class="math inline">\(H_1\)</span> which is to the left of the decision boundary. That means there’s some chance that even if <span class="math inline">\(H_1\)</span> is true we’ll claim that we can’t disprove the null! That’s a false negative, or a missed result! The point of enrolling more people in the trial is to minimize the size of that area and increase the area of the distribution of <span class="math inline">\(H_1\)</span> that’s to the right of the decision boundary, which is called the power.</p>
<p><strong>Client:</strong> How is that possible?</p>
<p><strong>Consultant:</strong> You can see above that the difference in means of the two histograms is the effect size, which is a fixed quantity that we don’t know and can’t change, so there’s no way to shift the distribution of <span class="math inline">\(H_1\)</span> to the right. In a power calculation, we have to start by assuming an effect size. Since you already did a pilot study, let’s stick with the result you got: <span class="math inline">\(p_T = 0.2, p_C = 0.1\)</span>. What we can change is how “fat” the two curves are. The way we do that is by enrolling more and more subjects. The more subjects are in the study, the less likely it becomes that a large enough group of them would be more or less relational at baseline and also be all assigned to the same group by random chance. That makes each of the densities taller and narrower, which moves the decision boundary to the left at the same time as it shrinks the area of the distribution that’s to the left of it.</p>
<p><strong>Client:</strong> Oh… that makes sense to me. So the question then is how many subjects do we have to have so that a large enough portion of the density (let’s say 90%) is to the right of the decision boundary? But how do we know exactly how the number of subjects affects these curves? How do we even get these curves?</p>
<p><strong>Consultant:</strong> That’s exactly right. In many cases there are theoretical ways to derive what the curves will look like, but often the easiest thing to do is to simulate them using the exact same model that we proposed to analyze the data.</p>
<p><strong>Client:</strong> You lost me.</p>
<p><strong>Consultant:</strong> We talked earlier about modeling this problem with a binomial distribution… remember the coin flips? We can generate some number of fake subjects’ data in R by sampling from that distribution using <code>rbinom</code>.</p>
<p>What we’re going to do now is make lots of fake datasets where we’ll set <span class="math inline">\(p_T = p_C = 0.1\)</span>. We’ll then run our logistic regression analysis on each of those and get the value of the coefficient. At the end we’ll have a bunch of coefficients, which we can turn into a histogram…</p>
<p><strong>Client:</strong> Oh! That’s the distribution of the coefficient under <span class="math inline">\(H_0\)</span>! And then we’ll do the same thing, generating fake datasets of size <span class="math inline">\(N\)</span> with <span class="math inline">\(p_T = 0.2\)</span> and <span class="math inline">\(p_C = 0.1\)</span>, which will give us the distribution under the alternative hypothesis.</p>
<p><strong>Consultant:</strong> Exactly. Then you set the cutoff by finding the value of the coefficient for which the top 5% of the estimates from the null scenario are greater than it, and then you find what percentage of the estimates from the alternate scenario are greater than that cutoff and that’s your power. To find how many subjects you need, all you need to do is repeat that process with different values for <span class="math inline">\(N\)</span>. In each of those simulations, you’ll get an estimate for your power, so simply scan the results to find the power you want (90%) and pick the <span class="math inline">\(N\)</span> that resulted in that power.</p>
<p><strong>Client:</strong> That’s great! I think I’ll be able to code that in R once I read up about loops. One last detail: how do I handle the fact that each subject had a different number of total goals? How do I simulate how many total goals each fake subject will have?</p>
<p><strong>Consultant:</strong> Ah… that’s a great question… hmm…</p>
<p><strong>Client:</strong> Should I just pick a random number of total goals (<span class="math inline">\(n\)</span> in the binomial model) for each fake subject?</p>
<p><strong>Consultant:</strong> I suppose you could do that, but then you would have to choose a distribution to draw those random numbers from, which could be making a strong and untested assumption. Here’s another idea: for each fake subject, if they are to be part of the treated group, randomly pick a number of total goals from any of the treated subjects in your pilot data, and vice versa if they are to be a fake control subject. That way you aren’t making any assumptions about the data generating process for the number of goals and you’re taking into account potential differences in the treatment arms. We call this process bootstrap sampling.</p>
<p><strong>Client:</strong> I like that.</p>
<p><strong>Consultant:</strong> Actually, you could even bootstrap the entire power calculation, forgoing the modeling with <code>rbinom</code>. You could take two bootstrap samples from the pilot control group as the fake treated and control subjects to get the null distribution. Then take a bootstrap sample from the pilot treated group to be the fake treated subjects and a bootstrap sample from the pilot control subjects to be the fake control subjects in order to get the alternative distribution. Like before, calculate the power and then repeat with different <span class="math inline">\(N\)</span> to see how power changes with the size of your study. A different way to get the null would be to shuffle the outcomes between your two groups in the pilot data and sample from that pool, but I’m not sure at first glance if that’s better or worse, or if it will make that much of a difference. It might be worthwhile to try all three approaches (parametric, bootstrap, and bootstrap with permutation) and see if they all generally agree.</p>
<p><strong>Client:</strong> That’s fantastic. I need to take some time to process all of this and code some of it up and see what I get. Thanks so much for your help! I’ve learned a ton and I think I could use a lot of this for some of my other research as well!</p>
<p><strong>Consultant:</strong> Happy to be of service!</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>